{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steuerungs-Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter\n",
    "\n",
    "#Speicherort der Test-Daten for example './GTSRB/Training'\n",
    "TRAINING_DATA_PATH = \"Z:/Daten/Universität/DSKI_Projektarbeit/DATA_DSKI_Projekt/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images\" #\"C:/Users/de136581/Documents/Uni/SoSe_2024/DSKI_Projekt/Data_trafic_Signs/Final_Training/GTSRB/Final_Training/Images\" \n",
    "\n",
    "#Ist momentan nicht nötig\n",
    "TEST_DATA_PATH = \"Z:/Daten/Universität/DSKI_Projektarbeit/DATA_DSKI_Projekt/GTSRB_Online-Test-Images/GTSRB/Online-Test/Images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeine Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reading the images\n",
    "# arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "# returns: list of images, list of corresponding labels \n",
    "def readTrafficSigns(rootpath):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        next(gtReader) # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            images.append(plt.imread(prefix + row[0])) # the 1th column is the filename\n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return images, labels\n",
    "\n",
    "def format_imgs(imgs_lst):\n",
    "    new_size = (32, 32)\n",
    "    resized_images = []\n",
    "    for img in imgs_lst:\n",
    "        resized_img = resize(img, new_size, anti_aliasing=True)\n",
    "        resized_images.append(resized_img)\n",
    "\n",
    "    return np.array(resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapper Funktion Klassennummer - Verkehrszeichen\n",
    "def get_traffic_sign_name(class_id):\n",
    "    # Dictionary that maps class IDs to traffic sign names in German\n",
    "    class_id_to_name = {\n",
    "        0: \"Geschwindigkeitsbegrenzung (20km/h)\",\n",
    "        1: \"Geschwindigkeitsbegrenzung (30km/h)\",\n",
    "        2: \"Geschwindigkeitsbegrenzung (50km/h)\",\n",
    "        3: \"Geschwindigkeitsbegrenzung (60km/h)\",\n",
    "        4: \"Geschwindigkeitsbegrenzung (70km/h)\",\n",
    "        5: \"Geschwindigkeitsbegrenzung (80km/h)\",\n",
    "        6: \"Ende der Geschwindigkeitsbegrenzung (80km/h)\",\n",
    "        7: \"Geschwindigkeitsbegrenzung (100km/h)\",\n",
    "        8: \"Geschwindigkeitsbegrenzung (120km/h)\",\n",
    "        9: \"Überholverbot\",\n",
    "        10: \"Überholverbot für Fahrzeuge über 3,5 Tonnen\",\n",
    "        11: \"Vorfahrt an der nächsten Kreuzung\",\n",
    "        12: \"Vorfahrtstraße\",\n",
    "        13: \"Vorfahrt gewähren\",\n",
    "        14: \"Halt\",\n",
    "        15: \"Verbot für Fahrzeuge\",\n",
    "        16: \"Verbot für Fahrzeuge über 3,5 Tonnen\",\n",
    "        17: \"Einfahrt verboten\",\n",
    "        18: \"Allgemeine Gefahr\",\n",
    "        19: \"Gefährliche Kurve nach links\",\n",
    "        20: \"Gefährliche Kurve nach rechts\",\n",
    "        21: \"Doppelkurve\",\n",
    "        22: \"Unebene Fahrbahn\",\n",
    "        23: \"Schleudergefahr bei Nässe oder Schmutz\",\n",
    "        24: \"Fahrbahnverengung\",\n",
    "        25: \"Baustelle\",\n",
    "        26: \"Ampel\",\n",
    "        27: \"Fußgänger\",\n",
    "        28: \"Kinder\",\n",
    "        29: \"Radfahrer\",\n",
    "        30: \"Schnee- oder Eisglätte\",\n",
    "        31: \"Wildwechsel\",\n",
    "        32: \"Ende aller Streckenverbote\",\n",
    "        33: \"Rechts abbiegen\",\n",
    "        34: \"Links abbiegen\",\n",
    "        35: \"Geradeaus\",\n",
    "        36: \"Geradeaus oder rechts\",\n",
    "        37: \"Geradeaus oder links\",\n",
    "        38: \"Rechts vorbei\",\n",
    "        39: \"Links vorbei\",\n",
    "        40: \"Kreisverkehr\",\n",
    "        41: \"Ende des Überholverbots\",\n",
    "        42: \"Ende des Überholverbots für Fahrzeuge über 3,5 Tonnen\"\n",
    "    }\n",
    "    \n",
    "    # Return the name of the traffic sign corresponding to the given class ID\n",
    "    return class_id_to_name.get(class_id, \"Unbekannte Klassennummer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dateneinlesen\n",
    "\n",
    "für alle Klassifizierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainings und Testdaten vorbereiten\n",
    "trainImages, trainLabels =  readTrafficSigns(TRAINING_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binäre Klassifikation\n",
    "\n",
    "Es soll nun zu Beginn ein Klassifikator gebaut werden, der Bilder des GTSRB-Datensatzes danach klassifiziert, ob diese zur Klasse 1 (Geschwindigkeitsbegrenzung (30km/h)) gehört.\n",
    "\n",
    "Hierfür muss der Datensatz vorbereitet werden; Die Trainings- und Test-Daten müssen den neuen Klassen (true, false) bzw (1,0) zugeordnet werden. Anschließend müssen die Bilder noch die notwendigen Vorverarbeitungsschritte durchlaufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = np.where( np.array(trainLabels) == 1, 1, 0)\n",
    "# Train-Test-Aufteilung\n",
    "bin_img_train, bin_img_test, bin_labels_train, bin_labels_test = train_test_split(trainImages,  bin_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Daten normalisieren\n",
    "bin_img_train = format_imgs(bin_img_train) / 255\n",
    "bin_img_test = format_imgs(bin_img_test) / 255\n",
    "\n",
    "# Labels zu kategorischen Daten umwandeln\n",
    "bin_labels_train = to_categorical(bin_labels_train, 2)\n",
    "bin_labels_test = to_categorical(bin_labels_test, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen eines CNN-Modell mit der Sequential API von Keras. \n",
    "\n",
    "Das Modell besteht aus:\n",
    "- Zwei Convolutional-Schichten (Conv2D) mit ReLU-Aktivierung und Max-Pooling-Schichten (MaxPooling2D).\n",
    "- Einer Flatten-Schicht (Flatten), um die 2D-Feature-Maps in einen 1D-Vektor umzuwandeln.\n",
    "- Einer voll verbundenen Schicht (Dense) mit 128 Neuronen und einer Dropout-Schicht (Dropout), um Overfitting zu reduzieren.\n",
    "- Einer Ausgabeschicht mit Softmax-Aktivierung, die für binäre Klassifikation geeignet ist.\n",
    "\n",
    "Das Modell wird mit dem adam Optimierer kompiliert, der für schnelle Konvergenz bekannt ist. Die Verlustfunktion binary_crossentropy wird für die binäre Klassifikation verwendet, und die Metrik accuracy wird zur Bewertung des Modells genutzt.\n",
    "\n",
    "Anschließend wird das Modell mit den Trainingsdaten 'bin_img_train' und 'bin_labels_train' trainiert. Das Training erfolgt über 10 Epochen mit einer Batch-Größe von 32. Die Validierungsdaten bin_img_test und bin_labels_test werden verwendet, um die Leistung des Modells während des Trainings zu überwachen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-Modell erstellen\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),   # Faltungsschicht mit 32 Filtern, 3x3 Kernel, ReLU-Aktivierung, Eingabeform (32, 32, 3)\n",
    "    MaxPooling2D((2, 2)),                                             # Max-Pooling-Schicht mit 2x2 Pooling-Fenster\n",
    "    Conv2D(64, (3, 3), activation='relu'),                            # Weitere Faltungsschicht mit 64 Filtern, 3x3 Kernel, ReLU-Aktivierung\n",
    "    MaxPooling2D((2, 2)),                                             # Weitere Max-Pooling-Schicht mit 2x2 Pooling-Fenster\n",
    "    Flatten(),                                                        # Umwandeln der 2D-Feature-Maps in 1D-Feature-Vektor\n",
    "    Dense(128, activation='relu'),                                    # Voll verbundene Schicht (Dense Layer) mit 128 Neuronen und ReLU-Aktivierung\n",
    "    Dropout(0.5),                                                     # Dropout-Schicht zur Reduktion von Overfitting, 50% Dropout-Rate\n",
    "    Dense(2, activation='softmax')                                    # Ausgabeschicht mit 2 Neuronen und Softmax-Aktivierung für binäre Klassifikation\n",
    "])\n",
    "\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modell trainieren\n",
    "bin_history = model.fit(bin_img_train, bin_labels_train, epochs=10, validation_data=(bin_img_test, bin_labels_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gütemaß Genauigkeit (Accuracy) vs. Verlust (Loss)\n",
    "\n",
    "In diesem Code werden verschiedene Gütemaße verwendet, um die Leistung des CNN-Modells zu bewerten. Diese Maße sind besonders wichtig, um zu verstehen, wie gut das Modell arbeitet und wo möglicherweise Verbesserungen notwendig sind. Die wichtigsten Gütemaße in diesem Kontext sind die Genauigkeit (Accuracy) und der Verlust (Loss).\n",
    "\n",
    "\n",
    "#### Genauigkeit (Accuracy)\n",
    "Die Genauigkeit ist ein Maß dafür, wie viele der Vorhersagen des Modells korrekt sind. Sie wird berechnet als der Anteil der korrekt klassifizierten Beispiele an der Gesamtzahl der Beispiele. Für binäre Klassifikation, wie in diesem Fall, kann die Genauigkeit folgendermaßen berechnet werden:\n",
    "\n",
    "$Genauigkeit = \\frac{Anzahl der korrekten Vorhersagen}{Gesamtzahl der Vorhersagen}$\n",
    "\n",
    "##### Bedeutung:\n",
    "- Hohe Genauigkeit: Das Modell trifft in den meisten Fällen die richtige Entscheidung.\n",
    "- Niedrige Genauigkeit: Das Modell macht viele Fehler und muss möglicherweise verbessert werden.\n",
    "\n",
    "\n",
    "\n",
    "#### Verlust (Loss)\n",
    "Der Verlust ist ein Maß dafür, wie schlecht das Modell während des Trainings abschneidet. Es handelt sich dabei um eine Funktion, die den Unterschied zwischen den tatsächlichen Labels und den vom Modell vorhergesagten Wahrscheinlichkeiten misst. In diesem Code wird der binary_crossentropy-Verlust verwendet.\n",
    "\n",
    "##### Bedeutung:\n",
    "- Niedriger Verlust: Die Vorhersagen des Modells sind näher an den tatsächlichen Labels, was ein Zeichen für ein gut funktionierendes Modell ist.\n",
    "- Hoher Verlust: Die Vorhersagen des Modells weichen stark von den tatsächlichen Labels ab, was auf ein schlecht funktionierendes Modell hindeutet.\n",
    "\n",
    "\n",
    "\n",
    "#### Trainingsgenauigkeit vs. Validierungsgenauigkeit\n",
    "Trainingsgenauigkeit: Dies ist die Genauigkeit, die das Modell auf den Trainingsdaten erreicht. Sie gibt an, wie gut das Modell die Trainingsdaten gelernt hat.\n",
    "Validierungsgenauigkeit: Dies ist die Genauigkeit, die das Modell auf den Validierungsdaten erreicht. Sie gibt an, wie gut das Modell auf unbekannten Daten generalisiert.\n",
    "\n",
    "##### Bedeutung der Unterscheidung:\n",
    "- Hohe Trainingsgenauigkeit, aber niedrige Validierungsgenauigkeit: Dies deutet auf Overfitting hin, was bedeutet, dass das Modell die Trainingsdaten gut gelernt hat, aber Schwierigkeiten hat, auf neuen, unbekannten Daten gut zu generalisieren.\n",
    "- Ähnliche Trainings- und Validierungsgenauigkeit: Dies deutet darauf hin, dass das Modell sowohl auf den Trainingsdaten als auch auf den Validierungsdaten gut funktioniert und wahrscheinlich gut generalisiert.\n",
    "\n",
    "Trainingsverlust vs. Validierungsverlust\n",
    "Trainingsverlust: Dies ist der Verlust, den das Modell auf den Trainingsdaten hat. Ein niedriger Trainingsverlust zeigt, dass das Modell die Trainingsdaten gut gelernt hat.\n",
    "Validierungsverlust: Dies ist der Verlust, den das Modell auf den Validierungsdaten hat. Ein niedriger Validierungsverlust zeigt, dass das Modell gut auf unbekannten Daten funktioniert.\n",
    "Bedeutung der Unterscheidung:\n",
    "Hoher Trainingsverlust: Das Modell hat Schwierigkeiten, die Trainingsdaten zu lernen.\n",
    "Hoher Validierungsverlust: Das Modell generalisiert nicht gut auf neue Daten.\n",
    "Insgesamt sind Genauigkeit und Verlust zwei der am häufigsten verwendeten Gütemaße zur Bewertung von Modellen, da sie ein umfassendes Bild davon geben, wie gut das Modell funktioniert. Hohe Genauigkeit und niedriger Verlust sowohl beim Training als auch bei der Validierung sind Anzeichen für ein gut funktionierendes Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellbewertung\n",
    "val_loss, val_acc = model.evaluate(bin_img_test, bin_labels_test)\n",
    "print(f'Validation accuracy: {val_acc}')\n",
    "\n",
    "plt.plot(bin_history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(bin_history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Multiclass\n",
    "Im Folgenden soll ein Convolutional Neural Network (CNN) für die Multiklassen-Klassifikation von Verkehrszeichen trainiert und bewertet werden\n",
    "\n",
    "### Datenaufbereitung und Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Aufteilung / wobei 20% der Daten für das Testset verwendet werden. Die random_state=42 sorgt dafür, dass die Aufteilung reproduzierbar ist.\n",
    "img_train, img_test, labels_train, labels_test = train_test_split(trainImages,  trainLabels, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-Hot-Encoding der Labels\n",
    "# Die Labels werden in One-Hot-Vektoren umgewandelt, um sie für die Multiklassen-Klassifikation vorzubereiten. Es gibt 43 Klassen für die verschiedenen Verkehrszeichen.\n",
    "labels_train = to_categorical(labels_train, 43)\n",
    "labels_test = to_categorical(labels_test, 43)\n",
    "\n",
    "#Bilder formatieren, damit sie in das Modell eingespeist werden können\n",
    "img_train = format_imgs(img_train)\n",
    "img_test = format_imgs(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration des Datensatzes:\n",
    "# Wähle ein zufälliges Bild aus dem Trainingsdatensatz \n",
    "random_index = np.random.randint(0, len(img_train))\n",
    "bsp_image = img_train[random_index]\n",
    "bsp_label = labels_train[random_index]\n",
    "\n",
    "# Zeige das Bild an\n",
    "plt.imshow(bsp_image.squeeze(), cmap='gray')\n",
    "plt.title(f\"Zufälliges Testbild der Klasse: {get_traffic_sign_name(np.argmax(bsp_label))}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellen des Modells\n",
    "Erstellen eines CNN-Modell mit der Sequential API von Keras. \n",
    "\n",
    "Es besteht aus:\n",
    "\n",
    "- Einer Convolutional-Schicht (Conv2D) mit ReLU-Aktivierung und einer Max-Pooling-Schicht (MaxPooling2D).\n",
    "- Einer Flatten-Schicht (Flatten), um die 2D-Feature-Maps in einen 1D-Vektor umzuwandeln.\n",
    "- Einer voll verbundenen Schicht (Dense) mit 128 Neuronen und einer weiteren Dense-Schicht mit 43 Neuronen und Softmax-Aktivierung für die 43 Klassen.\n",
    "\n",
    "Anschließend wird das Modell mit dem adam Optimierer kompiliert, der für schnelle Konvergenz bekannt ist. Die Metrik accuracy wird zur Bewertung des Modells genutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellarchitektur\n",
    "# Definiere das Modell\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))   # Faltungsschicht mit 32 Filtern, 3x3 Kernel, ReLU-Aktivierung, Eingabeform (32, 32, 3)\n",
    "model.add(layers.MaxPooling2D((2, 2)))                                             # Max-Pooling-Schicht mit 2x2 Pooling-Fenster\n",
    "model.add(layers.Flatten())                                                        # Umwandeln der 2D-Feature-Maps in 1D-Feature-Vektor\n",
    "model.add(layers.Dense(128, activation='relu'))                                    # Voll verbundene Schicht (Dense Layer) mit 128 Neuronen und ReLU-Aktivierung\n",
    "model.add(layers.Dense(43, activation='softmax'))                                  # Ausgabeschicht mit 43 Neuronen und Softmax-Aktivierung für Multiklassen-Klassifikation\n",
    "\n",
    "\n",
    "# Kompiliere das Modell\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(img_train, labels_train, epochs=10, batch_size=32, validation_data=(img_test, labels_test)) #, validation_data=(img_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell-Evaluation\n",
    "\n",
    "Im Folgenden soll unser erstelltes Modell evaluiert werden. Wir wollen also bestimmen, wie gut unser Trainiertes Modell Bilder des Test-Datensatzes erkennt.\n",
    "\n",
    "Dazu betrachten wir einmal ein zufällig ausgewähltes Bild und die vom Modell vorhergesagte Klasse:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testen des Modells:\n",
    "    \n",
    "# Wähle ein zufälliges Bild aus dem Testdatensatz\n",
    "random_index = np.random.randint(0, len(img_test))\n",
    "test_image = img_test[random_index]\n",
    "true_label = labels_test[random_index]\n",
    "\n",
    "# Zeige das Bild an\n",
    "plt.imshow(test_image.squeeze(), cmap='gray')\n",
    "plt.title(f\"Zufälliges Testbild der Klasse: {get_traffic_sign_name(np.argmax(true_label))}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Klassifiziere das Bild mit dem trainierten Modell\n",
    "predicted_probs = model.predict(np.expand_dims(test_image, axis=0))\n",
    "predicted_class = np.argmax(predicted_probs)\n",
    "\n",
    "# Gib die Klassifizierung und die Wahrscheinlichkeit aus\n",
    "print(f\"Vorhergesagte Klasse: {get_traffic_sign_name(np.argmax(true_label))}\")\n",
    "print(f\"Wahrscheinlichkeit: {predicted_probs[0][predicted_class]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird das trainierte Modell anhand der Testdaten bewertet. Der Validierungsverlust (val_loss) und die Validierungsgenauigkeit (val_acc) werden wie oben erläutert berechnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellbewertung\n",
    "val_loss, val_acc = model.evaluate(img_test, labels_test)\n",
    "print(f'Validation accuracy: {val_acc}')\n",
    "\n",
    "# Plotten der Trainingsgeschichte\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gütemaße"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen für die Testdaten\n",
    "y_pred = model.predict(img_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(labels_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Bewertung von Modellen zur Multiklassen-Klassifikation, wie in dem gegebenen Beispiel, sind verschiedene Gütemaße relevant. Zu den wichtigsten gehören **Accuracy (Genauigkeit)**, **Precision (Präzision)**, **Recall (Sensitivität)** und **F1-Score**. Diese Metriken bieten verschiedene Perspektiven auf die Leistung des Modells und helfen dabei, Stärken und Schwächen in der Klassifikation zu identifizieren.\n",
    "\n",
    "#### 1. Accuracy (Genauigkeit)\n",
    "Die Accuracy gibt den Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen an. Für Multiklassen-Klassifikation wird sie wie folgt berechnet:\n",
    "\n",
    "$ \\text{Accuracy} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{1}\\left( y_i = \\hat{y}_i \\right) $\n",
    "\n",
    "\n",
    "\n",
    "wobei:\n",
    "- $N$ die Gesamtzahl der Instanzen ist,\n",
    "- $y_i$ das wahre Label der $i$-ten Instanz ist,\n",
    "- $ \\hat{y}_i $ das vorhergesagte Label der $i$-ten Instanz ist,\n",
    "- $ \\mathbb{1} $ eine Indikatorfunktion ist, die 1 ist, wenn die Bedingung wahr ist, und 0, wenn sie falsch ist.\n",
    "\n",
    "#### 2. Precision (Präzision)\n",
    "Precision misst den Anteil der korrekt klassifizierten positiven Instanzen an allen Instanzen, die als positiv klassifiziert wurden. Für eine Klasse $ k $ in der Multiklassen-Klassifikation wird die Präzision wie folgt berechnet:\n",
    "\n",
    "$ \\text{Precision}_k = \\frac{\\text{TP}_k}{\\text{TP}_k + \\text{FP}_k} $\n",
    "\n",
    "\n",
    "\n",
    "wobei:\n",
    "- $ \\text{TP}_k $ die Anzahl der True Positives für Klasse $ k $ ist,\n",
    "- $ \\text{FP}_k $ die Anzahl der False Positives für Klasse $ k $ ist.\n",
    "\n",
    "#### 3. Recall (Sensitivität)\n",
    "Recall misst den Anteil der korrekt klassifizierten positiven Instanzen an allen tatsächlich positiven Instanzen. Für eine Klasse $ k $ wird der Recall wie folgt berechnet:\n",
    "\n",
    "$ \\text{Recall}_k = \\frac{\\text{TP}_k}{\\text{TP}_k + \\text{FN}_k} $\n",
    "\n",
    "wobei:\n",
    "- $ \\text{TP}_k $ die Anzahl der True Positives für Klasse $ k $ ist,\n",
    "- $ \\text{FN}_k $ die Anzahl der False Negatives für Klasse $ k $ ist.\n",
    "\n",
    "#### 4. F1-Score\n",
    "Der F1-Score ist das harmonische Mittel von Precision und Recall. Er bietet eine Balance zwischen Precision und Recall und wird wie folgt berechnet:\n",
    "\n",
    "$ \\text{F1-Score}_k = 2 \\cdot \\frac{\\text{Precision}_k \\cdot \\text{Recall}_k}{\\text{Precision}_k + \\text{Recall}_k} $\n",
    "\n",
    "In LaTeX-Schreibweise:\n",
    "\n",
    "$ \\text{F1-Score}_k = 2 \\cdot \\frac{\\text{Precision}_k \\cdot \\text{Recall}_k}{\\text{Precision}_k + \\text{Recall}_k} $\n",
    "\n",
    "#### Vergleich zwischen Multiklassen- und Binärer Klassifikation\n",
    "In der binären Klassifikation gibt es nur zwei Klassen, häufig als positiv und negativ bezeichnet. Die Berechnungen für Precision, Recall und F1-Score sind daher einfacher und beziehen sich auf eine positive Klasse.\n",
    "\n",
    "Für Multiklassen-Klassifikation wird jede Klasse als \"positiv\" betrachtet, während alle anderen Klassen als \"negativ\" betrachtet werden. Dies führt zu individuellen Precision-, Recall- und F1-Score-Werten für jede Klasse. Zur Gesamtevaluierung können diese Metriken auf zwei Weisen aggregiert werden:\n",
    "\n",
    "1. **Mikro-Mittelwert**: Betrachtet alle Klassen als gleich und summiert die einzelnen True Positives, False Positives und False Negatives über alle Klassen hinweg, bevor die Metriken berechnet werden.\n",
    "\n",
    "   In LaTeX-Schreibweise für Precision:\n",
    "\n",
    "   $ \\text{Precision}_{\\text{micro}} = \\frac{\\sum_{k} \\text{TP}_k}{\\sum_{k} (\\text{TP}_k + \\text{FP}_k)} $\n",
    "\n",
    "2. **Makro-Mittelwert**: Berechnet die Metriken für jede Klasse und nimmt dann den Durchschnitt dieser Metriken. Jede Klasse wird gleich gewichtet, unabhängig von ihrer Größe.\n",
    "\n",
    "   In LaTeX-Schreibweise für Precision:\n",
    "\n",
    "   $ \\text{Precision}_{\\text{macro}} = \\frac{1}{K} \\sum_{k=1}^{K} \\text{Precision}_k $\n",
    "\n",
    "   wobei $ K $ die Anzahl der Klassen ist.\n",
    "\n",
    "#### Zusammenfassung\n",
    "- **Accuracy**: Gesamte korrekte Vorhersagen. Für binäre und Multiklassen-Klassifikation identisch berechnet.\n",
    "- **Precision**: Fokus auf die Qualität der positiven Vorhersagen. In der Multiklassen-Klassifikation für jede Klasse separat berechnet.\n",
    "- **Recall**: Fokus auf die Erfassung der tatsächlichen positiven Instanzen. In der Multiklassen-Klassifikation für jede Klasse separat berechnet.\n",
    "- **F1-Score**: Balance zwischen Precision und Recall. In der Multiklassen-Klassifikation für jede Klasse separat berechnet.\n",
    "\n",
    "Durch die Verwendung dieser Gütemaße kann ein umfassendes Bild der Modellleistung gewonnen werden, was für die Verbesserung und Feinabstimmung von Modellen in der Praxis unerlässlich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metriken ausgeben\n",
    "report = classification_report(y_true, y_pred_classes, target_names=[f'Class {i}' for i in range(43)])\n",
    "print(report)\n",
    "\n",
    "# Gütemaße für das gesamte Modell berechnen und ausgeben\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "macro_precision = precision_score(y_true, y_pred_classes, average='macro')\n",
    "macro_recall = recall_score(y_true, y_pred_classes, average='macro')\n",
    "macro_f1 = f1_score(y_true, y_pred_classes, average='macro')\n",
    "weighted_precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "weighted_recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "weighted_f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Macro-Averaged Precision: {macro_precision:.4f}')\n",
    "print(f'Macro-Averaged Recall: {macro_recall:.4f}')\n",
    "print(f'Macro-Averaged F1 Score: {macro_f1:.4f}')\n",
    "print(f'Weighted-Averaged Precision: {weighted_precision:.4f}')\n",
    "print(f'Weighted-Averaged Recall: {weighted_recall:.4f}')\n",
    "print(f'Weighted-Averaged F1 Score: {weighted_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Eine **Konfusionsmatrix** (Oft auch Wahrheitsmatrix genannt) ist ein weiteres grundlegendes Werkzeug zur Bewertung der Leistung eines Klassifikationsmodells. Sie zeigt auf, wie oft das Modell jede Klasse korrekt oder falsch vorhergesagt hat und ermöglicht es, die Leistung in einer strukturierten und übersichtlichen Form zu analysieren.\n",
    "\n",
    "### Aufbau einer Konfusionsmatrix\n",
    "\n",
    "Für eine Klassifikation mit $N$ Klassen ist die Konfusionsmatrix eine $N \\times N$ Matrix, in der:\n",
    "\n",
    "- Die Zeilen die tatsächlichen Klassen repräsentieren.\n",
    "- Die Spalten die vorhergesagten Klassen repräsentieren.\n",
    "\n",
    "Jede Zelle $M[i, j]$ in der Matrix gibt die Anzahl der Beobachtungen an, die zur tatsächlichen Klasse $i$ gehören und als Klasse $j$ vorhergesagt wurden.\n",
    "\n",
    "### Beispiel einer Konfusionsmatrix\n",
    "\n",
    "Für eine binäre Klassifikation kann die Konfusionsmatrix wie folgt aussehen:\n",
    "\n",
    "\n",
    "\\begin{array}{c|cc}\n",
    "\\text{Aktuelle Klasse} & \\text{Vorhergesagte Klasse Positiv} & \\text{Vorhergesagte Klasse Negativ} \\\\\n",
    "\\hline\n",
    "\\text{Positiv} & \\text{TP} & \\text{FN} \\\\\n",
    "\\text{Negativ} & \\text{FP} & \\text{TN}\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "Für eine Multiklassen-Klassifikation, z.B. mit drei Klassen, könnte die Matrix so aussehen:\n",
    "\n",
    "\n",
    "\\begin{array}{c|ccc}\n",
    "\\text{Aktuelle Klasse} & \\text{Vorhergesagte Klasse A} & \\text{Vorhergesagte Klasse B} & \\text{Vorhergesagte Klasse C} \\\\\n",
    "\\hline\n",
    "\\text{A} & 50 & 2 & 1 \\\\\n",
    "\\text{B} & 10 & 40 & 5 \\\\\n",
    "\\text{C} & 0 & 3 & 47 \\\\\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "### Berechnung und Interpretation\n",
    "\n",
    "Die Berechnung der Konfusionsmatrix erfolgt durch Vergleich der tatsächlichen Klassen mit den vorhergesagten Klassen für jede Instanz im Datensatz. Aus der Konfusionsmatrix lassen sich die eben erklärten Leistungskennzahlen berechnen:\n",
    "- **Accuracy**: Gesamtgenauigkeit des Modells.\n",
    "- **Precision (Präzision)**: Wie viele der als positiv klassifizierten Instanzen tatsächlich positiv sind.\n",
    "- **Recall (Sensitivität)**: Wie viele der tatsächlichen positiven Instanzen korrekt klassifiziert wurden.\n",
    "- **F1-Score**: Harmonisches Mittel von Precision und Recall.\n",
    "\n",
    "Diese Metriken werden hier wie folgt berechnet:\n",
    "\n",
    "$\n",
    "\\text{Accuracy} = \\frac{\\sum_{i} M[i, i]}{\\sum_{i} \\sum_{j} M[i, j]}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{Precision}_k = \\frac{M[k, k]}{\\sum_{i} M[i, k]}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{Recall}_k = \\frac{M[k, k]}{\\sum_{j} M[k, j]}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{F1-Score}_k = 2 \\cdot \\frac{\\text{Precision}_k \\cdot \\text{Recall}_k}{\\text{Precision}_k + \\text{Recall}_k}\n",
    "$\n",
    "\n",
    "### Anwendung der Konfusionsmatrix\n",
    "\n",
    "Die Konfusionsmatrix hilft dabei, die Leistung eines Modells detailliert zu analysieren. Sie zeigt an, welche Klassen häufig miteinander verwechselt werden, und gibt Hinweise darauf, wo das Modell verbessert werden könnte. Beispielsweise können systematische Fehler identifiziert und gezielt Maßnahmen ergriffen werden, um die Klassifikationsgenauigkeit zu erhöhen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix berechnen\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Confusion Matrix normalisieren\n",
    "# die Matrix wird normalisiert, um Anteile anstelle von absoluten Werten anzuzeigen.\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "conf_matrix_normalized = np.nan_to_num(conf_matrix_normalized)  # Replace NaNs with 0\n",
    "\n",
    "# Funktion zum Formatieren der Werte\n",
    "def format_func(value):\n",
    "    if value == 0:\n",
    "        return '0'\n",
    "    elif value < 0.0001:  # Wert < 0.01%\n",
    "        return ''\n",
    "    else:\n",
    "        return f'{value:.2%}'\n",
    "\n",
    "# Confusion Matrix visualisieren\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(conf_matrix_normalized, fmt='', cmap='Blues', xticklabels=range(43), yticklabels=range(43),\n",
    "            annot_kws={\"size\": 7}, cbar=False, linewidths=.5, linecolor='black')\n",
    "\n",
    "# Set custom annotations\n",
    "for i in range(conf_matrix_normalized.shape[0]):\n",
    "    for j in range(conf_matrix_normalized.shape[1]):\n",
    "        plt.text(j + 0.5, i + 0.5, format_func(conf_matrix_normalized[i, j]),\n",
    "                 horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# X-Achse am oberen Rand platzieren\n",
    "plt.gca().xaxis.set_ticks_position('top')\n",
    "plt.ylabel('Actual-Classes')\n",
    "plt.title('Normalized Confusion Matrix for GTSRB Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix visualisieren\n",
    "plt.figure(figsize=(25, 25))\n",
    "sns.heatmap(conf_matrix_normalized, annot=True, cmap='Blues', xticklabels=range(43), yticklabels=range(43)) #, fmt='.2%'\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual-Class')\n",
    "plt.title('Normalized Confusion Matrix for GTSRB Classification')\n",
    "plt.show()\n",
    "\n",
    "# Zusätzliche Metriken ausgeben\n",
    "print(classification_report(y_true, y_pred_classes, target_names=[f'Class {i}' for i in range(43)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM als Klassifizierer\n",
    "\n",
    "neben den CNN ist ein ebenso weit verbreiter Classifier die SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für SVMs werden die Bilder in einem amderen Format benötigt, daher werden diese hier erneut formatiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = format_imgs(trainImages)\n",
    "labels = trainLabels\n",
    "\n",
    "# Überprüfen, ob alle Bilder die gleiche Größe haben\n",
    "print(\"Bildgröße:\", np.array(images).shape)  # Sollte (Anzahl_Bilder, 32, 32) sein\n",
    "\n",
    "# Daten normalisieren und in das richtige Format bringen\n",
    "# Bilder werden auf einen Bereich von 0 bis 1 normalisiert, indem sie durch 255 geteilt werden\n",
    "# Die Bilder werden in einen zweidimensionalen Vektor umgeformt\n",
    "X = np.array(images).reshape(len(images), -1) / 255.0\n",
    "y = np.array(labels)\n",
    "\n",
    "\n",
    "# Daten in Trainings- und Testdaten aufteilen\n",
    "# 80% der Daten werden für das Training verwendet, 20% für das Testen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Support Vector Machine (SVM) Modell mit linearem Kernel wird erstellt. Der Parameter C=1.0 reguliert den Einfluss von Fehlklassifikationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Modell erstellen\n",
    "# Wir erstellen ein Support Vector Machine (SVM) Modell mit einem linearen Kernel\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen auf den Testdaten\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Genauigkeit berechnen\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Genauigkeit: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Klassifikationsbericht anzeigen\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich SVM vs CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das trainierte CNN und die SVM zu vergleichen und zu beurteilen, welches Modell besser für die Klassifizierung von Straßenschildern geeignet ist, gehen wir folgendermaßen vor:\n",
    "\n",
    "1. **Ergebnisse des CNN-Modells zusammenfassen:**\n",
    "   - Genauigkeit (Accuracy)\n",
    "   - Precision, Recall und F1-Score\n",
    "   - Visualisierung der Trainingsgeschichte (Accuracy und Loss)\n",
    "   - Confusion Matrix\n",
    "\n",
    "2. **Ergebnisse des SVM-Modells zusammenfassen:**\n",
    "   - Genauigkeit (Accuracy)\n",
    "   - Precision, Recall und F1-Score\n",
    "   - Confusion Matrix\n",
    "\n",
    "3. **Vergleich und Beurteilung der beiden Modelle:**\n",
    "\n",
    "### Ergebnisse des CNN-Modells\n",
    "Angenommen, das CNN wurde bereits wie folgt trainiert und evaluiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation des CNN-Modells\n",
    "val_loss, val_acc = model.evaluate(img_test, labels_test)\n",
    "print(f'CNN Validation accuracy: {val_acc}')\n",
    "\n",
    "# Klassifikationsbericht für CNN\n",
    "y_pred_cnn = model.predict(img_test)\n",
    "y_pred_classes_cnn = np.argmax(y_pred_cnn, axis=1)\n",
    "y_true_cnn = np.argmax(labels_test, axis=1)\n",
    "print(classification_report(y_true_cnn, y_pred_classes_cnn))\n",
    "\n",
    "# Confusion Matrix für CNN\n",
    "conf_matrix_cnn = confusion_matrix(y_true_cnn, y_pred_classes_cnn)\n",
    "conf_matrix_normalized_cnn = conf_matrix_cnn.astype('float') / conf_matrix_cnn.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(conf_matrix_normalized_cnn, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Normalized Confusion Matrix for CNN Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnisse des SVM-Modells\n",
    "Das SVM-Modell wurde bereits wie folgt trainiert und evaluiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation des SVM-Modells\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'SVM Validation accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Klassifikationsbericht für SVM\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix für SVM\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix_normalized_svm = conf_matrix_svm.astype('float') / conf_matrix_svm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(conf_matrix_normalized_svm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Normalized Confusion Matrix for SVM Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergleich und Beurteilung\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
